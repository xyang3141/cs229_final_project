{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3fd957-3e6e-4353-b114-2bd998c795dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/opt/conda/lib/python3.7/site-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c109ClassType6createENS_8optionalINS_13QualifiedNameEEESt8weak_ptrIN5torch3jit15CompilationUnitEEbSs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18905/2493583244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchtext/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transforms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchtext/experimental/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegexTokenizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mRegexTokenizerPybind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencePiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSentencePiecePybind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /opt/conda/lib/python3.7/site-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c109ClassType6createENS_8optionalINS_13QualifiedNameEEESt8weak_ptrIN5torch3jit15CompilationUnitEEbSs"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82579a81-4035-4a17-acfe-3cfb3f61953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8d617-d7c6-45af-99f5-213d574843e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bb21f-2852-4645-8984-4f295db6dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(batch_first = True, use_vocab = False, tokenize = tokenize_and_cut, \n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids, init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx, pad_token = pad_token_idx, unk_token = unk_token_idx)\n",
    "LABEL = data.LabelField()\n",
    "\n",
    "fields = [('text', TEXT), ('label', LABEL)]\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'sentiment_3_new_tweet',\n",
    "                                        train = 'train.csv',\n",
    "                                        validation = 'valid.csv',\n",
    "                                        test = 'test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee93fdb-ceef-41a7-9fc1-2a21effcb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cdf1a-ca52-4dee-9110-573fe3601eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff350b1-feac-4376-8311-65832e6da9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50a6a3-6a44-4443-adcc-c49632bf1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort = False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938d3a8-425d-4a4d-8a55-062c121b4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016fcd4-b95e-4125-8b71-02986412a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d65231-88a2-47b1-8b0a-cfe4ddfe8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 3\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a24565-8df3-4433-abac-a484513c645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6c941-6182-4d32-8607-197590a6ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae134006-c151-4ca0-8f01-e0577c2ddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e73922-83b2-43ab-8c91-845f794107bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.argmax(torch.softmax(preds, 1), dim=1)\n",
    "    correct = (rounded_preds == (y)).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6998d81-b0d4-45de-b9be-d3afd7c88f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, precision, recall, f1\n",
    "\n",
    "def compute_metrics(preds, y):\n",
    "    \"\"\"\n",
    "    Returns precision, recall, F1-score of per batch\n",
    "    \"\"\"\n",
    "    class_preds = torch.argmax(torch.softmax(preds, 1), dim=1)\n",
    "    return (accuracy(class_preds, y), \n",
    "            precision(class_preds, y, num_classes=3, average='macro'), \n",
    "            recall(class_preds, y, num_classes=3, average='macro'), \n",
    "            f1(class_preds, y, num_classes=3, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a8c73-a85b-492e-ade9-f4061b4288a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "    batches = len(iterator)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc, prec, recall, f1 = compute_metrics(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_prec += prec.item()\n",
    "        epoch_recall += recall.item()\n",
    "        epoch_f1 += f1.item()\n",
    "        \n",
    "    return epoch_loss/batches, epoch_acc/batches, epoch_prec/batches, epoch_recall/batches, epoch_f1/batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1225778-8b24-45cf-9207-2ce856fe48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "    batches = len(iterator)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc, prec, recall, f1 = compute_metrics(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_prec += prec.item()\n",
    "            epoch_recall += recall.item()\n",
    "            epoch_f1 += f1.item()\n",
    "        \n",
    "    return epoch_loss/batches, epoch_acc/batches, epoch_prec/batches, epoch_recall/batches, epoch_f1/batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b1837-bf2c-4926-a1b7-3a3c64188973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b6a11-817d-491c-92bd-91593332c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "train_loss = np.zeros(N_EPOCHS)\n",
    "train_acc = np.zeros(N_EPOCHS)\n",
    "train_prec = np.zeros(N_EPOCHS)\n",
    "train_recall = np.zeros(N_EPOCHS)\n",
    "train_f1 = np.zeros(N_EPOCHS)\n",
    "valid_loss = np.zeros(N_EPOCHS)\n",
    "valid_acc = np.zeros(N_EPOCHS)\n",
    "valid_prec = np.zeros(N_EPOCHS)\n",
    "valid_recall = np.zeros(N_EPOCHS)\n",
    "valid_f1 = np.zeros(N_EPOCHS)\n",
    "\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss[i], train_acc[i], train_prec[i], train_recall[i], train_f1[i] = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss[i], valid_acc[i], valid_prec[i], valid_recall[i], valid_f1[i] = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss[i] < best_valid_loss:\n",
    "        best_valid_loss = valid_loss[i]\n",
    "        torch.save(model.state_dict(), 'tut8-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {i+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss[i]:.3f} | Train Acc: {train_acc[i]*100:.2f}% | Train Prec: {train_prec[i]*100:.2f}% | Train Recall: {train_recall[i]*100:.2f}% | Train F1: {train_f1[i]*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss[i]:.3f} |  Val. Acc: {valid_acc[i]*100:.2f}% |  Val. Prec: {valid_prec[i]*100:.2f}% |  Val. Recall: {valid_recall[i]*100:.2f}% | Val.  F1: {valid_f1[i]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4d4fa-0e79-40a1-b690-0ef36077e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut8-model.pt'))\n",
    "\n",
    "test_loss, test_acc, test_prec, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test prec: {test_prec*100:.2f}% |Test Recall: {test_recall*100:.2f}% | Test F1: {test_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e5cfe-5785-4a0b-9c5e-5848504ffd5f",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6cc5f-b351-4063-b090-2de170f92a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_singleSentence(model, tokenizer, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor)).cpu().detach().numpy()\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "def predict_sentiment(model, sentences):\n",
    "    pred_res = []\n",
    "    for i, sentence in sentences.items():\n",
    "        pred_res.append(predict_singleSentence(model, tokenizer, sentence))\n",
    "    return pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fcd21-b19f-4016-b2c7-225de50bd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import interp\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def prec_rec_curve(model, X, Y_true, titile=\"\"):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    n_classes = 3\n",
    "    y_test = label_binarize(Y_true, classes=[2, 3, 4])\n",
    "    predict_res = predict_sentiment(model, X)\n",
    "    y_score = label_binarize(predict_res, classes=[2, 0, 1])\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    micro_auc = roc_auc_score(y_test, y_score, average='micro')\n",
    "    \n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    macro_auc = roc_auc_score(y_test, y_score, average='macro')\n",
    "\n",
    "    print(roc_auc)\n",
    "    print('micro auc:', micro_auc)\n",
    "    print('macro auc:', macro_auc)\n",
    "    \n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('figures/BERT_ROC.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ee3a9-c2a4-49fc-9a6b-a64b876d3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"sentiment_3_new_tweet/test.csv\", header=None)\n",
    "\n",
    "prec_rec_curve(model, test_df[0], test_df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7285059-789e-490e-992b-447af7473740",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d66bc-0636-4a22-ab37-b3dca7d0ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_pred = predict_sentiment(model,  test_df[0])\n",
    "y_test_pred = np.array([int(LABEL.vocab.itos[label]) for label in y_test_pred])\n",
    "y_test_true = test_df[1].apply(int).values\n",
    "cm = confusion_matrix(y_test_pred, y_test_true, normalize='true')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea85b8-36bc-4d1a-9220-9443266fa8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True\n",
    "cmap = 'RdPu'\n",
    "classes = [0, 1, 2]\n",
    "title = 'Cofusion Matrix'\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "ax.figure.colorbar(im, ax = ax)\n",
    "ax.set(xticks = np.arange(cm.shape[1]), yticks = np.arange(cm.shape[0]), xticklabels = classes, yticklabels = classes, ylabel = 'True label', xlabel = 'Predicted label', title = title)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha = 'right', rotation_mode = 'anchor')\n",
    "fmt = '.2f' if normalize else 'd'\n",
    "thresh = cm.max() / 2\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt), ha = 'center', va = 'center', color = 'white' if cm[i,j] > thresh else 'black')\n",
    "        fig.tight_layout()\n",
    "plt.savefig('figures/BERT_CM.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a987c2-ab17-490e-8256-5c10465d8bf0",
   "metadata": {},
   "source": [
    "### Metric Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01974eea-b105-4ccf-a2b0-ef2d3fdc2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "totEpoch = N_EPOCHS\n",
    "x = range(0, totEpoch)\n",
    "plt.figure(figsize=(14,4))\n",
    "grid = plt.GridSpec(3, 2, wspace=0.5, hspace=0.5)\n",
    "plt.subplot(grid[:,0])\n",
    "# plt.plot(x, F1_list_train, color=\"b\", marker='o',markersize='1.5',markeredgecolor='b',markeredgewidth = 1.5, label = 'Train F1 score')\n",
    "plt.plot(x, train_f1, color=\"r\", marker='o',markersize='1.5',markeredgecolor='r',markeredgewidth = 1.5, label = 'Train F1 score')\n",
    "plt.plot(x, valid_f1, color=\"b\", marker='o',markersize='1.5',markeredgecolor='b',markeredgewidth = 1.5, label = 'Valid F1 score')\n",
    "plt.legend()\n",
    "plt.title('F1 Score vs Epoches')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.subplot(grid[:,1])\n",
    "plt.plot(x, train_loss, color=\"red\", marker='o',markersize='1.5',markeredgecolor='r',markeredgewidth = 1.5, label = 'Train Loss')\n",
    "plt.plot(x, valid_loss, color=\"blue\", marker='o',markersize='1.5',markeredgecolor='b',markeredgewidth = 1.5, label = 'Valid Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss vs Epoches')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('figures/BERT_Loss_F1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e228569-241a-4322-857f-56db309a1047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
