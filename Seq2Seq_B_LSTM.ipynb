{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22488312-e162-47ce-855e-7d5858351bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0d9f1e-edaa-4f7c-b7b8-5e877a6071ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (8,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "START, END = '2021-1-1', '2021-11-25'\n",
    "data_tweet = pd.read_csv(\"covidvaccine_tweet_sentiment_veracity_BERT.csv\", index_col=['date'], parse_dates=['date'])\n",
    "data_vaccine = pd.read_csv(\"COVID-19_Vaccination_Trends_Population.csv\", index_col=['Date'], parse_dates=['Date'], thousands=',')\n",
    "data_tweet = data_tweet.loc[START:END]\n",
    "data_vaccine = data_vaccine.loc[START:END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87736afe-b21b-4f60-89cb-66855b7f4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel\n",
    "data_tweet['sentiment_score'] = data_tweet['sentiment_score'] - 1\n",
    "data_tweet['veracity'] = data_tweet['veracity'].apply(lambda x : -1 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912345d8-d790-4cb5-b682-5d3e18031cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divided by states\n",
    "vaccine_by_state = {}\n",
    "tweet_by_state = {}\n",
    "locs = data_tweet['user_location'].unique()\n",
    "for i in range(len(locs)):\n",
    "    loc = locs[i]\n",
    "    tmp = data_tweet[data_tweet['user_location'] == loc]\n",
    "    if len(tmp) > 500:\n",
    "        tweet_by_state[loc] = tmp\n",
    "        vaccine_by_state[loc] = data_vaccine[data_vaccine['Location']==loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91288bf-910e-4905-9dd8-a592394322a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Calculate Tweet Impact\n",
    "def tweet_impact(state, f1, f2):\n",
    "    table = tweet_by_state[state]\n",
    "    sentiment = ((f1 * np.sqrt(table['user_followers'])) * table['sentiment_score']).resample('1D').mean()\n",
    "    veracity = ((f2 * np.sqrt(table['user_followers'])) * table['veracity']).resample('1D').mean()\n",
    "    # impact = table['sentiment_score']\n",
    "    return sentiment, veracity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cd20f-94fc-4d7e-9f02-e80bf11d7ba8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "F1 = 0.4\n",
    "F2 = 0.7\n",
    "WINDOW = '4D'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "impact_score = []\n",
    "vaccination_rate = []\n",
    "for state in tweet_by_state:\n",
    "    # Calculate Tweet Impact\n",
    "    s1 = pd.Series(index=pd.date_range(start=START, end=END, freq='1D'))\n",
    "    s2 = pd.Series(index=pd.date_range(start=START, end=END, freq='1D'))\n",
    "    sentiment, veracity = tweet_impact(state, F1, F2)\n",
    "    sentiment, veracity = sentiment.ewm(com=0.7).mean(), veracity.ewm(com=0.7).mean()\n",
    "    s1[sentiment.index] = sentiment\n",
    "    s2[veracity.index] = veracity\n",
    "    s1.interpolate(method='polynomial', order=2, inplace=True)\n",
    "    s2.interpolate(method='polynomial', order=2, inplace=True)\n",
    "    s1 = s1.resample(WINDOW).mean()\n",
    "    s2 = s2.resample(WINDOW).mean()\n",
    "    impact_score.append([s1.tolist(),s2.tolist()])\n",
    "    \n",
    "    # Calculate vaccination rate\n",
    "    vaccine = vaccine_by_state[state]\n",
    "    # TODO Chooses \"Administration\" or \"Report\" date type\n",
    "    vaccine = vaccine[vaccine['date_type'] == \"Admin\"]\n",
    "    vaccine = vaccine.resample(WINDOW).mean()\n",
    "    vaccine = vaccine.ewm(com=2).mean()\n",
    "    vaccination_rate.append(vaccine['Administered_Daily'] / vaccine['Population'] * 100)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(range(len(impact_score[4][0])), impact_score[4][0])\n",
    "plt.plot(range(len(impact_score[4][0])), impact_score[4][1])\n",
    "plt.figure(2)\n",
    "plt.plot(range(len(vaccination_rate[4])), vaccination_rate[4])\n",
    "\n",
    "impact_score = np.array(impact_score)[:,:,:-2]\n",
    "vaccination_rate = np.array(vaccination_rate)[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1571e7-72e4-4543-895d-d6afb4e88251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 2, 81)\n",
      "(33, 81)\n"
     ]
    }
   ],
   "source": [
    "print(impact_score.shape)\n",
    "print(vaccination_rate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf2786-e63f-4146-8e9d-604befd287b6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5124ebde-bf2b-4ea9-aac7-1ab98b92d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.functional import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fe0ffee-52d2-481a-883c-d24c9293acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x_train = np.transpose(impact_score, (0,2,1))\n",
    "y_train = vaccination_rate.reshape(vaccination_rate.shape[0], vaccination_rate.shape[1], -1)\n",
    "\n",
    "# x_train = np.concatenate((x_train,y_train),axis=2)\n",
    "x_train = y_train.copy()\n",
    "\n",
    "tmp_train = np.zeros((x_train.shape[0], x_train.shape[1], 3))\n",
    "poly = PolynomialFeatures(2)\n",
    "for i in range(x_train.shape[1]):\n",
    "    tmp_train[:,i,:] = poly.fit_transform(x_train[:,i,:])\n",
    "x_train = tmp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79a5c4e8-8f2a-4aea-9e93-122f19b5af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 81, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b40a34b-cd93-4639-9c3f-addb46ea1f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_PAST=20\n",
    "N_FUTURE=10\n",
    "\n",
    "def split_series(series_x, series_y, n_past, n_future):\n",
    "    x, y = [], []\n",
    "    for train_start in range(len(series_x)):\n",
    "        train_end = train_start + n_past\n",
    "        valid_start = train_end\n",
    "        valid_end = valid_start + n_future\n",
    "        if valid_end > len(series_y):\n",
    "            break\n",
    "        past, feture = series_x[train_start:train_end,:], series_y[valid_start:valid_end,:]\n",
    "        x.append(past)\n",
    "        y.append(feture)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "tmp_x, tmp_y = split_series(x_train[0], y_train[0], N_PAST, N_FUTURE)\n",
    "for i in range(1, len(x_train)):\n",
    "    sample_x, sample_y = split_series(x_train[i], y_train[i], N_PAST, N_FUTURE)\n",
    "    tmp_x = np.concatenate((tmp_x, sample_x), axis=0)\n",
    "    tmp_y = np.concatenate((tmp_y, sample_y), axis=0)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(tmp_x, tmp_y, shuffle=True, train_size=0.8)\n",
    "x_train, y_train = torch.from_numpy(x_train).float().to(device), torch.from_numpy(y_train).float().to(device)\n",
    "x_valid, y_valid = torch.from_numpy(x_valid).float().to(device), torch.from_numpy(y_valid).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e45eda06-6e5c-4912-8834-27f6c07dbcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1372, 20, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97cc71-567a-4476-9126-bdeb87a440e0",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c159953-4c03-4469-a143-e9a4871300db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, ouput_len, n_layers, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.ouput_len = ouput_len\n",
    "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers = n_layers, dropout = dropout, batch_first = True)\n",
    "        \n",
    "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, num_layers = n_layers, dropout = dropout, batch_first = True)\n",
    "        \n",
    "        self.timedistribute = TimeDistributed(nn.Linear(hidden_dim, output_dim) , batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "\n",
    "        #data = [batch size, sent len, input_dim]\n",
    "        \n",
    "        data = self.bn1(data.permute(0,2,1)).permute(0,2,1)\n",
    "        \n",
    "        encode_output, (hidden, cell) = self.encoder(data)\n",
    "        \n",
    "        encode_output = encode_output[:,-1,:].unsqueeze(1)\n",
    "        encode_output = encode_output.repeat(1, self.ouput_len, 1)\n",
    "        \n",
    "        decode_output, _ = self.decoder(encode_output, (hidden, cell))\n",
    "        \n",
    "        return self.timedistribute(decode_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9db8ca1e-2adc-434c-a73c-6a4fed041370",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 3\n",
    "HIDDEN_DIM = 300\n",
    "OUTPUT_DIM = 1\n",
    "OUTPUT_LEN = 10\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = RNN(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, OUTPUT_LEN, N_LAYERS, DROPOUT)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-3)\n",
    "criterion = torch.nn.HuberLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a87a863-d2e1-422f-8841-82e4c1ca25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2(preds, y):\n",
    "    r2 = 0\n",
    "    n = len(preds)\n",
    "    for i in range(n):\n",
    "        r2 += r2_score(preds[i], y[i])\n",
    "    return r2/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32eb1139-a3ab-4d4c-99a0-c8244fe0d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, Y, optimizer, criterion):    \n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predictions = model(X)\n",
    "\n",
    "    loss = criterion(predictions, Y)\n",
    "    r2 = compute_r2(predictions.squeeze(2), Y.squeeze(2))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss.item(), r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cc27beb-ad60-4dde-9059-47097818a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, Y)\n",
    "        r2 = compute_r2(predictions.squeeze(2), Y.squeeze(2))\n",
    "    return loss.item(), r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f635161c-e79b-4633-839a-abd5bb03435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a9f07f2-6a38-4822-bdf8-dfe008432094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef73a79c-0916-4ca4-9bde-fd13644c6aa0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.578\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.729\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.471\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.738\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.649\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.816\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.750\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.811\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.478\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.750\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.729\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.899\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.783\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.809\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.474\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.879\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.777\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.678\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.429\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.737\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.558\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.082\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -1.130\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.648\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -0.562\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.495\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -1.084\n",
      "\t Val. Loss: 0.002 |  Val. R2: -2.422\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -2.620\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.683\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.763\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.081\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.853\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.257\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.045\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.911\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.781\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.779\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.564\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.715\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.663\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.909\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.003\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.637\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.677\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.713\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.582\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.834\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.833\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.092\n",
      "Epoch: 26 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.124\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.675\n",
      "Epoch: 27 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.637\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.641\n",
      "Epoch: 28 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.653\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.002\n",
      "Epoch: 29 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.888\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.989\n",
      "Epoch: 30 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.622\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.885\n",
      "Epoch: 31 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.606\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.848\n",
      "Epoch: 32 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.771\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.711\n",
      "Epoch: 33 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.569\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.629\n",
      "Epoch: 34 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.471\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.630\n",
      "Epoch: 35 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.563\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.628\n",
      "Epoch: 36 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.500\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.682\n",
      "Epoch: 37 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.415\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.756\n",
      "Epoch: 38 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.572\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.696\n",
      "Epoch: 39 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.570\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.609\n",
      "Epoch: 40 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.508\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.622\n",
      "Epoch: 41 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.513\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.652\n",
      "Epoch: 42 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.586\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.652\n",
      "Epoch: 43 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.454\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.659\n",
      "Epoch: 44 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.502\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.631\n",
      "Epoch: 45 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.489\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.633\n",
      "Epoch: 46 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.425\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.643\n",
      "Epoch: 47 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.381\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.615\n",
      "Epoch: 48 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.579\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.564\n",
      "Epoch: 49 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.400\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.621\n",
      "Epoch: 50 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.483\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.716\n",
      "Epoch: 51 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.692\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.553\n",
      "Epoch: 52 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.496\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.605\n",
      "Epoch: 53 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.455\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.730\n",
      "Epoch: 54 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.604\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.775\n",
      "Epoch: 55 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.537\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.609\n",
      "Epoch: 56 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.493\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.586\n",
      "Epoch: 57 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.510\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.644\n",
      "Epoch: 58 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.344\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.701\n",
      "Epoch: 59 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.509\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.711\n",
      "Epoch: 60 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.673\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.556\n",
      "Epoch: 61 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.386\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.654\n",
      "Epoch: 62 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.612\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.846\n",
      "Epoch: 63 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.804\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.715\n",
      "Epoch: 64 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.436\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.696\n",
      "Epoch: 65 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.471\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.716\n",
      "Epoch: 66 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.478\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.666\n",
      "Epoch: 67 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.449\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.654\n",
      "Epoch: 68 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.657\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.498\n",
      "Epoch: 69 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.405\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.649\n",
      "Epoch: 70 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.370\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.911\n",
      "Epoch: 71 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.805\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.812\n",
      "Epoch: 72 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.459\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.589\n",
      "Epoch: 73 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.495\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.941\n",
      "Epoch: 74 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.947\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.629\n",
      "Epoch: 75 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.491\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.650\n",
      "Epoch: 76 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.470\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.805\n",
      "Epoch: 77 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.769\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.587\n",
      "Epoch: 78 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.396\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.561\n",
      "Epoch: 79 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.360\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.703\n",
      "Epoch: 80 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.655\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.667\n",
      "Epoch: 81 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.552\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.681\n",
      "Epoch: 82 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.406\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.730\n",
      "Epoch: 83 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.469\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.688\n",
      "Epoch: 84 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.556\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.674\n",
      "Epoch: 85 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.571\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.775\n",
      "Epoch: 86 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.765\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.786\n",
      "Epoch: 87 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.560\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.659\n",
      "Epoch: 88 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.464\n",
      "\t Val. Loss: 0.001 |  Val. R2: -1.263\n",
      "Epoch: 89 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.394\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.510\n",
      "Epoch: 90 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.541\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.628\n",
      "Epoch: 91 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.481\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.833\n",
      "Epoch: 92 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.741\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.619\n",
      "Epoch: 93 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.526\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.637\n",
      "Epoch: 94 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.627\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.745\n",
      "Epoch: 95 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.725\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.641\n",
      "Epoch: 96 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.403\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.742\n",
      "Epoch: 97 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.431\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.836\n",
      "Epoch: 98 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.761\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.678\n",
      "Epoch: 99 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.708\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.804\n",
      "Epoch: 100 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.565\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.610\n",
      "Epoch: 101 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.542\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.214\n",
      "Epoch: 102 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.127\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.742\n",
      "Epoch: 103 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.434\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.614\n",
      "Epoch: 104 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.517\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.249\n",
      "Epoch: 105 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.136\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.766\n",
      "Epoch: 106 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.392\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.885\n",
      "Epoch: 107 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.434\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.867\n",
      "Epoch: 108 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.756\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.552\n",
      "Epoch: 109 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.518\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.615\n",
      "Epoch: 110 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.461\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.836\n",
      "Epoch: 111 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.668\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.812\n",
      "Epoch: 112 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.688\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.712\n",
      "Epoch: 113 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.460\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.615\n",
      "Epoch: 114 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.375\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.640\n",
      "Epoch: 115 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.499\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.605\n",
      "Epoch: 116 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.449\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.511\n",
      "Epoch: 117 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.354\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.524\n",
      "Epoch: 118 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.447\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.629\n",
      "Epoch: 119 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.501\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.677\n",
      "Epoch: 120 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.471\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.611\n",
      "Epoch: 121 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.490\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.525\n",
      "Epoch: 122 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.407\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.507\n",
      "Epoch: 123 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.373\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.608\n",
      "Epoch: 124 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.500\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.633\n",
      "Epoch: 125 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.509\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.612\n",
      "Epoch: 126 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.388\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.573\n",
      "Epoch: 127 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.386\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.553\n",
      "Epoch: 128 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.432\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.598\n",
      "Epoch: 129 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.453\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.527\n",
      "Epoch: 130 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.464\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.530\n",
      "Epoch: 131 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.372\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.621\n",
      "Epoch: 132 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.406\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.723\n",
      "Epoch: 133 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.551\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.627\n",
      "Epoch: 134 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.420\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.560\n",
      "Epoch: 135 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.405\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.576\n",
      "Epoch: 136 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.353\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.583\n",
      "Epoch: 137 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.422\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.697\n",
      "Epoch: 138 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.589\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.525\n",
      "Epoch: 139 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.397\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.639\n",
      "Epoch: 140 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.365\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.636\n",
      "Epoch: 141 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.530\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.691\n",
      "Epoch: 142 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.631\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.551\n",
      "Epoch: 143 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.378\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.532\n",
      "Epoch: 144 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.415\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.639\n",
      "Epoch: 145 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.531\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.629\n",
      "Epoch: 146 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.392\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.588\n",
      "Epoch: 147 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.440\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.521\n",
      "Epoch: 148 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.439\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.514\n",
      "Epoch: 149 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.415\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.617\n",
      "Epoch: 150 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.536\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.599\n",
      "Epoch: 151 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.427\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.485\n",
      "Epoch: 152 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.431\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.574\n",
      "Epoch: 153 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.554\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.546\n",
      "Epoch: 154 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.318\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.655\n",
      "Epoch: 155 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.390\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.621\n",
      "Epoch: 156 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.475\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.547\n",
      "Epoch: 157 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.394\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.544\n",
      "Epoch: 158 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.434\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.557\n",
      "Epoch: 159 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.335\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.590\n",
      "Epoch: 160 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.434\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.533\n",
      "Epoch: 161 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.404\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.519\n",
      "Epoch: 162 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.341\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.519\n",
      "Epoch: 163 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.379\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.728\n",
      "Epoch: 164 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.639\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.626\n",
      "Epoch: 165 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.340\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.517\n",
      "Epoch: 166 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.345\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.763\n",
      "Epoch: 167 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.713\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.636\n",
      "Epoch: 168 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.316\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.843\n",
      "Epoch: 169 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.749\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.659\n",
      "Epoch: 170 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.367\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.531\n",
      "Epoch: 171 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.437\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.915\n",
      "Epoch: 172 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.939\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.734\n",
      "Epoch: 173 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.458\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.677\n",
      "Epoch: 174 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.400\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.796\n",
      "Epoch: 175 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.637\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.498\n",
      "Epoch: 176 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.364\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.475\n",
      "Epoch: 177 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.426\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.760\n",
      "Epoch: 178 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.674\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.811\n",
      "Epoch: 179 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.425\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.717\n",
      "Epoch: 180 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.542\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.515\n",
      "Epoch: 181 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.477\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.456\n",
      "Epoch: 182 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.375\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.582\n",
      "Epoch: 183 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.383\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.787\n",
      "Epoch: 184 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.514\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.704\n",
      "Epoch: 185 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.340\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.479\n",
      "Epoch: 186 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.424\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.536\n",
      "Epoch: 187 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.536\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.476\n",
      "Epoch: 188 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.385\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.607\n",
      "Epoch: 189 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.382\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.569\n",
      "Epoch: 190 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.363\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.512\n",
      "Epoch: 191 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.343\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.513\n",
      "Epoch: 192 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.389\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.562\n",
      "Epoch: 193 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.291\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.549\n",
      "Epoch: 194 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.360\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.537\n",
      "Epoch: 195 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.427\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.533\n",
      "Epoch: 196 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.282\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.518\n",
      "Epoch: 197 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.348\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.525\n",
      "Epoch: 198 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.310\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.585\n",
      "Epoch: 199 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.379\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.567\n",
      "Epoch: 200 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.362\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.518\n",
      "Epoch: 201 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.343\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.538\n",
      "Epoch: 202 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.428\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.517\n",
      "Epoch: 203 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.289\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.505\n",
      "Epoch: 204 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.399\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.540\n",
      "Epoch: 205 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.408\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.512\n",
      "Epoch: 206 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.295\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.474\n",
      "Epoch: 207 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.302\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.511\n",
      "Epoch: 208 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.357\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.546\n",
      "Epoch: 209 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.342\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.633\n",
      "Epoch: 210 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.406\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.647\n",
      "Epoch: 211 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -0.512\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.606\n",
      "Epoch: 212 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.526\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.716\n",
      "Epoch: 213 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.490\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.038\n",
      "Epoch: 214 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.920\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.324\n",
      "Epoch: 215 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.709\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.543\n",
      "Epoch: 216 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.483\n",
      "\t Val. Loss: 0.001 |  Val. R2: -1.179\n",
      "Epoch: 217 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.269\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.926\n",
      "Epoch: 218 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.675\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.825\n",
      "Epoch: 219 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.783\n",
      "\t Val. Loss: 0.001 |  Val. R2: -1.812\n",
      "Epoch: 220 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.797\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.018\n",
      "Epoch: 221 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.670\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.907\n",
      "Epoch: 222 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.820\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.506\n",
      "Epoch: 223 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.547\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.446\n",
      "Epoch: 224 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.314\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.764\n",
      "Epoch: 225 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.159\n",
      "\t Val. Loss: 0.001 |  Val. R2: -1.734\n",
      "Epoch: 226 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.560\n",
      "\t Val. Loss: 0.001 |  Val. R2: -1.072\n",
      "Epoch: 227 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.039\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.226\n",
      "Epoch: 228 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.822\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.834\n",
      "Epoch: 229 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.715\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.239\n",
      "Epoch: 230 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.222\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.753\n",
      "Epoch: 231 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.618\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.809\n",
      "Epoch: 232 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.632\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.519\n",
      "Epoch: 233 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.397\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.030\n",
      "Epoch: 234 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.913\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.825\n",
      "Epoch: 235 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.585\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.713\n",
      "Epoch: 236 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.590\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.103\n",
      "Epoch: 237 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.997\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.763\n",
      "Epoch: 238 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.540\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.690\n",
      "Epoch: 239 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.547\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.970\n",
      "Epoch: 240 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.882\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.721\n",
      "Epoch: 241 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.511\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.738\n",
      "Epoch: 242 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.497\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.004\n",
      "Epoch: 243 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.863\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.750\n",
      "Epoch: 244 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.531\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.713\n",
      "Epoch: 245 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.409\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.817\n",
      "Epoch: 246 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.675\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.659\n",
      "Epoch: 247 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.429\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.705\n",
      "Epoch: 248 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.370\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.689\n",
      "Epoch: 249 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.487\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.647\n",
      "Epoch: 250 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.507\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.638\n",
      "Epoch: 251 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.474\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.674\n",
      "Epoch: 252 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.552\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.642\n",
      "Epoch: 253 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.533\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.563\n",
      "Epoch: 254 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.376\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.568\n",
      "Epoch: 255 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.449\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.598\n",
      "Epoch: 256 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.472\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.652\n",
      "Epoch: 257 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.334\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.646\n",
      "Epoch: 258 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.420\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.651\n",
      "Epoch: 259 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.539\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.521\n",
      "Epoch: 260 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.410\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.558\n",
      "Epoch: 261 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.434\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.603\n",
      "Epoch: 262 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.470\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.585\n",
      "Epoch: 263 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.364\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.629\n",
      "Epoch: 264 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.490\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.594\n",
      "Epoch: 265 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.449\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.539\n",
      "Epoch: 266 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.345\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.536\n",
      "Epoch: 267 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.395\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.568\n",
      "Epoch: 268 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.341\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.620\n",
      "Epoch: 269 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.353\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.609\n",
      "Epoch: 270 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.355\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.600\n",
      "Epoch: 271 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.427\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.566\n",
      "Epoch: 272 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.351\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.606\n",
      "Epoch: 273 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.400\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.603\n",
      "Epoch: 274 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.326\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.593\n",
      "Epoch: 275 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.317\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.597\n",
      "Epoch: 276 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.401\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.543\n",
      "Epoch: 277 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.315\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.529\n",
      "Epoch: 278 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.319\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.575\n",
      "Epoch: 279 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.351\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.602\n",
      "Epoch: 280 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.344\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.587\n",
      "Epoch: 281 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.308\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.553\n",
      "Epoch: 282 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.329\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.548\n",
      "Epoch: 283 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.292\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.552\n",
      "Epoch: 284 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.299\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.553\n",
      "Epoch: 285 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.326\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.577\n",
      "Epoch: 286 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.275\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.564\n",
      "Epoch: 287 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.352\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.533\n",
      "Epoch: 288 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.320\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.547\n",
      "Epoch: 289 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.274\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.543\n",
      "Epoch: 290 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.320\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.781\n",
      "Epoch: 291 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.619\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.738\n",
      "Epoch: 292 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.380\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.535\n",
      "Epoch: 293 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.466\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.620\n",
      "Epoch: 294 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.563\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.723\n",
      "Epoch: 295 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.298\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.904\n",
      "Epoch: 296 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.690\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.653\n",
      "Epoch: 297 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.545\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.637\n",
      "Epoch: 298 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.371\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.387\n",
      "Epoch: 299 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.353\n",
      "\t Val. Loss: 0.001 |  Val. R2: -1.000\n",
      "Epoch: 300 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.989\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.656\n",
      "Epoch: 301 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.439\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.789\n",
      "Epoch: 302 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.392\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.503\n",
      "Epoch: 303 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.365\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.551\n",
      "Epoch: 304 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.502\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.513\n",
      "Epoch: 305 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.359\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.531\n",
      "Epoch: 306 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.339\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.558\n",
      "Epoch: 307 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.407\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.496\n",
      "Epoch: 308 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.259\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.516\n",
      "Epoch: 309 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.297\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.486\n",
      "Epoch: 310 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.341\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.527\n",
      "Epoch: 311 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.296\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.512\n",
      "Epoch: 312 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.295\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.648\n",
      "Epoch: 313 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.417\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.528\n",
      "Epoch: 314 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.241\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.465\n",
      "Epoch: 315 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.290\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.522\n",
      "Epoch: 316 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.400\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.536\n",
      "Epoch: 317 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.230\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.553\n",
      "Epoch: 318 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.327\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.509\n",
      "Epoch: 319 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.230\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.464\n",
      "Epoch: 320 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.299\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.494\n",
      "Epoch: 321 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.313\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.447\n",
      "Epoch: 322 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.293\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.479\n",
      "Epoch: 323 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.253\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.530\n",
      "Epoch: 324 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.233\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.540\n",
      "Epoch: 325 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.293\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.445\n",
      "Epoch: 326 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.213\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.445\n",
      "Epoch: 327 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.240\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.465\n",
      "Epoch: 328 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.250\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.625\n",
      "Epoch: 329 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.295\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.580\n",
      "Epoch: 330 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.331\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.507\n",
      "Epoch: 331 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.178\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.449\n",
      "Epoch: 332 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.281\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.624\n",
      "Epoch: 333 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.421\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.667\n",
      "Epoch: 334 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.242\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.529\n",
      "Epoch: 335 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.310\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.383\n",
      "Epoch: 336 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.257\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.421\n",
      "Epoch: 337 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.155\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.634\n",
      "Epoch: 338 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.453\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.641\n",
      "Epoch: 339 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.247\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.470\n",
      "Epoch: 340 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.184\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.437\n",
      "Epoch: 341 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.285\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.453\n",
      "Epoch: 342 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.176\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.612\n",
      "Epoch: 343 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.304\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.557\n",
      "Epoch: 344 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.186\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.461\n",
      "Epoch: 345 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.218\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.457\n",
      "Epoch: 346 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.224\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.498\n",
      "Epoch: 347 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.179\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.512\n",
      "Epoch: 348 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.206\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.463\n",
      "Epoch: 349 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.206\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.432\n",
      "Epoch: 350 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.157\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.477\n",
      "Epoch: 351 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.179\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.519\n",
      "Epoch: 352 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.194\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.507\n",
      "Epoch: 353 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.160\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.466\n",
      "Epoch: 354 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.228\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.445\n",
      "Epoch: 355 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.175\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.457\n",
      "Epoch: 356 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.164\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.486\n",
      "Epoch: 357 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.248\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.469\n",
      "Epoch: 358 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.162\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.448\n",
      "Epoch: 359 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.179\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.446\n",
      "Epoch: 360 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.208\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.492\n",
      "Epoch: 361 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.162\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.520\n",
      "Epoch: 362 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.266\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.453\n",
      "Epoch: 363 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.198\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.435\n",
      "Epoch: 364 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.117\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.562\n",
      "Epoch: 365 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.355\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.628\n",
      "Epoch: 366 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.123\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.537\n",
      "Epoch: 367 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.366\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.388\n",
      "Epoch: 368 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.195\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.509\n",
      "Epoch: 369 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.088\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.750\n",
      "Epoch: 370 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.475\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.728\n",
      "Epoch: 371 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.216\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.712\n",
      "Epoch: 372 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.546\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.452\n",
      "Epoch: 373 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.137\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.606\n",
      "Epoch: 374 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.157\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.653\n",
      "Epoch: 375 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.439\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.506\n",
      "Epoch: 376 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.232\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.456\n",
      "Epoch: 377 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.121\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.674\n",
      "Epoch: 378 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.473\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.562\n",
      "Epoch: 379 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.114\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.466\n",
      "Epoch: 380 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.199\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.609\n",
      "Epoch: 381 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.377\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.640\n",
      "Epoch: 382 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.181\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.845\n",
      "Epoch: 383 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.588\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.447\n",
      "Epoch: 384 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.111\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.341\n",
      "Epoch: 385 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.135\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.715\n",
      "Epoch: 386 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.488\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.690\n",
      "Epoch: 387 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.205\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.450\n",
      "Epoch: 388 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.162\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.729\n",
      "Epoch: 389 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.533\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.677\n",
      "Epoch: 390 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.185\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.501\n",
      "Epoch: 391 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.207\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.573\n",
      "Epoch: 392 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.444\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.462\n",
      "Epoch: 393 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.108\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.568\n",
      "Epoch: 394 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.214\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.561\n",
      "Epoch: 395 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.278\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.421\n",
      "Epoch: 396 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.078\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.552\n",
      "Epoch: 397 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.331\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.484\n",
      "Epoch: 398 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.115\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.387\n",
      "Epoch: 399 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.113\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.525\n",
      "Epoch: 400 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.369\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.593\n",
      "Epoch: 401 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.183\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.503\n",
      "Epoch: 402 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.178\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.522\n",
      "Epoch: 403 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.264\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.435\n",
      "Epoch: 404 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.074\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.480\n",
      "Epoch: 405 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.106\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.439\n",
      "Epoch: 406 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.169\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.401\n",
      "Epoch: 407 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.145\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.509\n",
      "Epoch: 408 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.153\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.451\n",
      "Epoch: 409 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.118\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.358\n",
      "Epoch: 410 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.069\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.476\n",
      "Epoch: 411 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.245\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.547\n",
      "Epoch: 412 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.089\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.435\n",
      "Epoch: 413 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.161\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.409\n",
      "Epoch: 414 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.153\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.421\n",
      "Epoch: 415 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.049\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.418\n",
      "Epoch: 416 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.094\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.395\n",
      "Epoch: 417 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.096\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.418\n",
      "Epoch: 418 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.064\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.435\n",
      "Epoch: 419 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.111\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.431\n",
      "Epoch: 420 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.066\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.384\n",
      "Epoch: 421 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.012\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.450\n",
      "Epoch: 422 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.141\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.446\n",
      "Epoch: 423 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.012\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.490\n",
      "Epoch: 424 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.176\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.379\n",
      "Epoch: 425 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.005\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.402\n",
      "Epoch: 426 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.208\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.362\n",
      "Epoch: 427 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.026\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.399\n",
      "Epoch: 428 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.056\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.427\n",
      "Epoch: 429 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.122\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.419\n",
      "Epoch: 430 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.039\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.486\n",
      "Epoch: 431 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.100\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.429\n",
      "Epoch: 432 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.065\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.796\n",
      "Epoch: 433 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.540\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.983\n",
      "Epoch: 434 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.321\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.806\n",
      "Epoch: 435 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.594\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.352\n",
      "Epoch: 436 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.174\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.604\n",
      "Epoch: 437 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.130\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.848\n",
      "Epoch: 438 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.464\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.454\n",
      "Epoch: 439 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.166\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.440\n",
      "Epoch: 440 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.076\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.442\n",
      "Epoch: 441 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.158\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.418\n",
      "Epoch: 442 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.098\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.496\n",
      "Epoch: 443 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.150\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.512\n",
      "Epoch: 444 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.134\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.388\n",
      "Epoch: 445 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.011\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.428\n",
      "Epoch: 446 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.000 | Train R2: -0.201\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.743\n",
      "Epoch: 447 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.345\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.945\n",
      "Epoch: 448 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -1.074\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.021\n",
      "Epoch: 449 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -0.660\n",
      "\t Val. Loss: 0.002 |  Val. R2: -2.091\n",
      "Epoch: 450 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -1.737\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.289\n",
      "Epoch: 451 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -0.816\n",
      "\t Val. Loss: 0.003 |  Val. R2: -2.457\n",
      "Epoch: 452 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.003 | Train R2: -2.160\n",
      "\t Val. Loss: 0.002 |  Val. R2: -2.574\n",
      "Epoch: 453 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -2.282\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.278\n",
      "Epoch: 454 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -1.090\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.232\n",
      "Epoch: 455 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -1.168\n",
      "\t Val. Loss: 0.002 |  Val. R2: -2.535\n",
      "Epoch: 456 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.002 | Train R2: -2.644\n",
      "\t Val. Loss: 0.002 |  Val. R2: -2.476\n",
      "Epoch: 457 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.959\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.554\n",
      "Epoch: 458 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.198\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.722\n",
      "Epoch: 459 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.743\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.494\n",
      "Epoch: 460 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.447\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.285\n",
      "Epoch: 461 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.921\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.860\n",
      "Epoch: 462 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.251\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.800\n",
      "Epoch: 463 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -1.168\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.132\n",
      "Epoch: 464 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.873\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.880\n",
      "Epoch: 465 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.796\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.931\n",
      "Epoch: 466 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.889\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.866\n",
      "Epoch: 467 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.684\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.983\n",
      "Epoch: 468 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.729\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.921\n",
      "Epoch: 469 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.752\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.904\n",
      "Epoch: 470 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.818\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.751\n",
      "Epoch: 471 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.554\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.805\n",
      "Epoch: 472 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.644\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.169\n",
      "Epoch: 473 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.993\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.932\n",
      "Epoch: 474 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.547\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.797\n",
      "Epoch: 475 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.455\n",
      "\t Val. Loss: 0.002 |  Val. R2: -1.159\n",
      "Epoch: 476 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.976\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.754\n",
      "Epoch: 477 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.547\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.705\n",
      "Epoch: 478 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.449\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.829\n",
      "Epoch: 479 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.730\n",
      "\t Val. Loss: 0.001 |  Val. R2: -0.675\n",
      "Epoch: 480 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.511\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.708\n",
      "Epoch: 481 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.396\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.729\n",
      "Epoch: 482 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.468\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.864\n",
      "Epoch: 483 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.568\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.776\n",
      "Epoch: 484 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.475\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.723\n",
      "Epoch: 485 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.430\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.721\n",
      "Epoch: 486 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.461\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.687\n",
      "Epoch: 487 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.379\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.666\n",
      "Epoch: 488 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.367\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.645\n",
      "Epoch: 489 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.415\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.589\n",
      "Epoch: 490 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.318\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.630\n",
      "Epoch: 491 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.391\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.679\n",
      "Epoch: 492 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.404\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.655\n",
      "Epoch: 493 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.391\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.592\n",
      "Epoch: 494 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.318\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.551\n",
      "Epoch: 495 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.297\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.565\n",
      "Epoch: 496 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.267\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.590\n",
      "Epoch: 497 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.270\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.587\n",
      "Epoch: 498 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.265\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.557\n",
      "Epoch: 499 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.260\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.549\n",
      "Epoch: 500 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.001 | Train R2: -0.215\n",
      "\t Val. Loss: 0.002 |  Val. R2: -0.563\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 500\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "train_loss = np.zeros(N_EPOCHS)\n",
    "train_r2 = np.zeros(N_EPOCHS)\n",
    "valid_loss = np.zeros(N_EPOCHS)\n",
    "valid_r2 = np.zeros(N_EPOCHS)\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss[i], train_r2[i] = train(model, x_train, y_train, optimizer, criterion)\n",
    "    valid_loss[i], valid_r2[i] = evaluate(model, x_valid, y_valid, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss[i] < best_valid_loss:\n",
    "        best_valid_loss = valid_loss[i]\n",
    "        torch.save(model.state_dict(), 'lstm-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {i+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss[i]:.3f} | Train R2: {train_r2[i]:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss[i]:.3f} |  Val. R2: {valid_r2[i]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4f05412-1f6a-4f96-a300-b0e6260cd5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('lstm-model.pt'))\n",
    "y_pred = predict(model, x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "079e0e8f-3242-46c5-850c-99c1b73759dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1 = y_pred[12].squeeze(1).detach().cpu().numpy()\n",
    "y2 = y_valid[12].squeeze(1).detach().cpu().numpy()\n",
    "plt.plot(range(len(y1)), y1, label='predict')\n",
    "plt.plot(range(len(y2)), y2, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660b9b-8dec-470b-83dc-1574d47f6ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
